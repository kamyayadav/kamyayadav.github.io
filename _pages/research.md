---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

My current projects and working papers include a formal model to explain when political parties in India introduce internal quotas for women candidates and an online survey experiment on incentivizing peer-to-peer correction of online misinformation. My dissertation project focuses on the political ambition of Indian women. 

Articles 
======

\emph{Multilateral Efforts on Information Integrity: Why Greater Definition is Needed}
======

_With Alicia Wanless and Samantha Lai_

\emph{Forthcoming} in Springer Handbook on Disinformation: A Multidisciplinary Analysis

\emph{What Makes an Influence Operation Malign? Leveraging Classification and Policy to Assess Digital Manipulation Campaigns}
======

_With Martin J. Riedl, Alicia Wanless, and Samuel Woolley_

The integrity of the information environment is essential to the health of democracies. Manipulation of it in efforts to influence audiences and outcomes threatens this integrity. At the same time, persuasion is a necessary tool in polities, including democratic ones, to encourage large groups of people to cooperate. This leads to an important question: How can influence operations be assessed in order to distinguish those that are acceptable from those that are not? This work explores possible criteria to objectively make such an assessment in the context of democracies using three case studies: U.S. efforts to sell the war in Iraq; interest-based campaigns related to climate change denial; and Narendra Modi’s WhatsApp-based BJP campaign for election in India. Each case study looks at six elements:  Who is behind such operations? What activities are being carried out? What is the quality of the content involved? Who is the target audience? What are the means of distribution? In so doing, this work explores three potential criteria that could act as objective metrics for assessing the acceptability of an influence operation in the context of democracies, namely: (1) transparency in origins; (2) quality of content; and (3) calls to action. 

[Carnegie Endowment for International Peace](https://carnegieendowment.org/2023/08/07/what-makes-influence-operation-malign-pub-90323)

\emph{How COVID Drove the Evolution of Fact-Checking}
======

_With Samikshya Siwakoti, Nicola Bariletto, Luca Zanotti, Ulas Erdogdu, and Jacob N. Shapiro_

With the outbreak of the coronavirus pandemic came a flood of novel misinformation. Ranging from harmless false cures to dangerous rhetoric targeting minorities, coronavirus-related misinformation spread quickly wherever the virus itself did. Fact-checking organizations around the world took up the charge against misinformation, essentially crowdsourcing the task of debunking false narratives. In many places, engagement with coronavirus-related content drove a large percentage of overall user engagement with fact-checking content, and the capacity organizations developed to address coronavirus-related misinformation was later deployed to debunk misinformation on other topics. 

[Harvard Kennedy School Misinformation Review](https://doi.org/10.37016/mr-2020-69)

\emph{Countries have more than 100 laws on the books to combat misinformation. How well do they work?}
======

_With Ulas Erdogdu, Samikshya Siwakoti, Jacob N. Shapiro, and Alicia Wanless_

Since 2015, there has been a huge increase in laws that ostensibly seek to counter misinformation. Since the pandemic began, this trend has only accelerated. Both authoritarian and democratic governments have introduced more new policies to fight misinformation in 2019 and in 2020. In authoritarian states pandemic-related misinformation provided a new justification for repressive policies. Questions of political motivations aside, as the continuing problem of pandemic misinformation illustrates, it’s unclear how effective these laws are.  

[Bulletin of the Atomic Scientists](https://doi.org/10.1080/00963402.2021.1912111)

\emph{Localized Misinformation in a Global Pandemic: Report on COVID-19 Narratives Around the World}
======

_With Samikshya Siwakoti, Isra Thange, Nicola Bariletto, Luca Zanotti, Alaa Ghoneim, and Jacob N. Shapiro_

The global reach of the pandemic creates a unique opportunity for a regional analysis of misinformation trends, allowing us to see how misinformation actors in different countries and cultural contexts respond to the same set of potential narrative conditions. Are the observed trends in misinformation similar or different? How is the pandemic interwoven with existing social narratives at the domestic and regional level to create new and potent misinformation? How does the regional spread of COVID-19 misinformation interact with regional and domestic fact-checking efforts, and how effective is the latter in curbing misinformation spread? This report will explore those questions while examining COVID-related misinformation, disinformation, and fact-checking capabilities in different regions around the world using data collected by the ESOC team on 5,613 distinct misinformation stories from the early days of the pandemic through the end of December 2020. Analysis of these stories reveals surprising patterns. Most importantly, we find that there is a great deal of heterogeneity in the nature of misinformation and disinformation across regions and countries. Contrary to what one might expect from the globalized nature of the information environment, the salient themes varied significantly across different regions and countries. Localized false narratives prevailed over global ones.  

[Empirical Studies of Conflict, Princeton University](https://esoc.princeton.edu/publications/localized-misinformation-global-pandemic-report-covid-19-narratives-around-world)

Working Papers
======

\emph{Seeking Truth: Incentivizing Peer to Peer Correction of Online Misinformation}
======

_With Rachel Xu_

Many approaches to tackling misinformation rely on interventions coordinated or managed by centralized authorities (e.g. media literacy campaigns and PSAs). There are two issues with such top-down interventions. First, there is a declining trust in authorities, especially fact-checkers and the media, who lead efforts in asserting accuracy on social media platforms. Second, these interventions are often expensive and not scalable. In order for misinformation resilience to be truly long-lasting and sustainable, misinformation interventions must find a way to be self-sustaining by the consumers of information – the public. We design and test an online intervention that encourages peer-to-peer correction of misinformation. We argue that social norm nudges – both descriptive and injunctive – motivate individuals to correct online misinformation through increasing acceptability of corrections and responsibility of corrections. We contribute to a growing literature on combating misinformation by proposing a durable and scalable intervention. 

\emph{When Gatekeepers Open the Gates: Internal Party Quotas as Reputation Building Strategies}
======

Why do political parties voluntarily adopt internal gender candidate quotas during high-stakes national elections? Existing literature provides electoral, ideological, strategic, and women's mobilization-related explanations for voluntary party quota adoption. Motivated by two Indian political parties' decision to adopt and implement over 33 percent quotas for women candidates in the 2019 election, I argue that parties are willing to incur short-term electoral losses if it leads to long-term gains. Through a formal model, I demonstrate that implementing quotas, in the absence of legislation mandating so and in the face of electoral costs, is a long-term reputation building strategy for political parties in single member district electoral systems. This paper contributes to the literature on why parties adopt gender quotas by providing an alternative strategic explanation. It provides a game theoretic lens to quota adoption as a reputation building strategy. 

_Contact for Working Paper._


